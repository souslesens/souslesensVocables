const fs = require("fs");
const knex = require("knex");
const path = require("path");
const yargs = require("yargs");

const migrateUserDataView = async (configDirectory, writeMode) => {
    const configPath = path.resolve(configDirectory, "mainConfig.json");
    const configJSON = JSON.parse(fs.readFileSync(configPath, { encoding: "utf-8" }));

    const userDataSchema = path.resolve("scripts", "sql", "003-user-data.sql");
    if (fs.existsSync(userDataSchema)) {
        const connection = await knex({ client: "pg", connection: configJSON.database });
        if (await connection.schema.hasColumn("user_data_list", "data_content")) {
            if (writeMode) {
                /* Remove the view since the library cannot do it on his own */
                await connection.schema.dropViewIfExists("user_data_list");
                /* Read the schema again to add the view again with the latest
                 * modification */
                await connection.raw(fs.readFileSync(userDataSchema, "utf-8"));
                connection.destroy();
                console.info(`The script ${userDataSchema} have beed executed`);
            } else {
                console.info(`Will run the script ${userDataSchema}`);
            }
        } else {
            console.info("The view is already up to date");
        }
    }
};

const main = async () => {
    const argv = yargs
        .alias("c", "config")
        .describe("c", "Path to the config directory")
        .alias("w", "write")
        .describe("w", "Write the migration in the file")
        .boolean("w")
        .demandOption(["config"])
        .help().argv;

    console.info(argv.write ? "ðŸš§ Prepare the migrationâ€¦" : "ðŸ”§ Dry run modeâ€¦");
    await migrateUserDataView(argv.config, argv.write);
};

main()
    .then(() => process.exit(0))
    .catch((err) => {
        console.error(err);
        process.exit(1);
    });
